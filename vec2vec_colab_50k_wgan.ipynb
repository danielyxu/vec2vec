{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vec2Vec: Colab Reproduction with WGAN Adversarial Loss (~50k Examples)\n",
        "\n",
        "This notebook reproduces and extends the main vec2vec experiment from the paper:\n",
        "**\"Harnessing the Universal Geometry of Embeddings\"** (Jha et al., 2025)\n",
        "\n",
        "## Experiment Details\n",
        "- **Source Model**: Stella (`stella` - unsupervised embedding model)\n",
        "- **Target Model**: GTE (`gte` - supervised embedding model)\n",
        "- **Dataset**: Natural Questions (NQ)\n",
        "- **Training Size**: ~50k examples (25k per encoder)\n",
        "- **Architecture**: ResNet MLP with adapters + adversarial training\n",
        "\n",
        "## Adversarial Loss Comparison\n",
        "We compare two adversarial training schemes:\n",
        "\n",
        "1. **Baseline (GAN)**: Standard GAN with least-squares loss (original vec2vec approach)\n",
        "2. **WGAN-GP**: Wasserstein GAN with gradient penalty\n",
        "   - Treats discriminators as critics with unbounded outputs\n",
        "   - Uses Wasserstein distance estimation\n",
        "   - Enforces Lipschitz constraint via gradient penalty\n",
        "\n",
        "The goal is to explore whether Wasserstein-style matching of embedding/latent distributions improves translation quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: nvidia-smi\n",
            "\n",
            "Python version: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]\n",
            "PyTorch version: 2.9.1\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Check GPU and environment\n",
        "!nvidia-smi\n",
        "\n",
        "import sys\n",
        "print(f\"\\nPython version: {sys.version}\")\n",
        "\n",
        "# Check CUDA availability\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "except ImportError:\n",
        "    print(\"PyTorch will be installed in the next step\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch\u001b[0m\u001b[31m\n",
            "\u001b[0mzsh:1: 4.29.0 not found\n",
            "zsh:1: 2.12.0 not found\n",
            "zsh:1: 0.20.0 not found\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Installed versions:\n",
            "  PyTorch: 2.9.1\n",
            "  Transformers: 4.57.1\n",
            "  Sentence-Transformers: 5.1.2\n",
            "  Accelerate: 1.11.0\n",
            "  CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "# Core packages for vec2vec\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q transformers>=4.29.0 sentence-transformers>=2.2.0\n",
        "!pip install -q datasets>=2.12.0 huggingface_hub>=0.15.0\n",
        "!pip install -q accelerate>=0.20.0\n",
        "!pip install -q wandb\n",
        "!pip install -q scikit-learn scipy matplotlib seaborn\n",
        "!pip install -q toml pandas\n",
        "!pip install -q nltk\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Installed versions:\n",
            "  PyTorch: 2.9.1\n",
            "  Transformers: 4.57.1\n",
            "  Sentence-Transformers: 5.1.2\n",
            "  Accelerate: 1.11.0\n",
            "  CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Verify installation\n",
        "import torch\n",
        "import transformers\n",
        "import sentence_transformers\n",
        "import accelerate\n",
        "\n",
        "print(f\"\\nInstalled versions:\")\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "print(f\"  Transformers: {transformers.__version__}\")\n",
        "print(f\"  Sentence-Transformers: {sentence_transformers.__version__}\")\n",
        "print(f\"  Accelerate: {accelerate.__version__}\")\n",
        "print(f\"  CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data & Embedding Preparation\n",
        "\n",
        "Vec2vec uses the **Natural Questions (NQ)** dataset from the BeIR benchmark. The embeddings are generated on-the-fly during training using the source (Stella) and target (GTE) embedding models.\n",
        "\n",
        "The data loading pipeline:\n",
        "1. Loads NQ corpus from HuggingFace datasets\n",
        "2. Splits into train/validation sets\n",
        "3. Creates tokenized batches for both encoders\n",
        "4. Generates embeddings during forward pass\n",
        "\n",
        "We'll use **25,000 samples per encoder** (50k total), which is sufficient to demonstrate the approach while keeping training time reasonable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting beir\n",
            "  Downloading beir-2.2.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: sentence-transformers in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from beir) (5.1.2)\n",
            "Collecting pytrec-eval-terrier (from beir)\n",
            "  Downloading pytrec_eval_terrier-0.5.10-cp311-cp311-macosx_10_9_universal2.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: datasets in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from beir) (4.4.1)\n",
            "Requirement already satisfied: filelock in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (2.3.4)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (0.4.0)\n",
            "Requirement already satisfied: pandas in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (2.3.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (2.32.5)\n",
            "Requirement already satisfied: httpx<1.0.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (0.70.18)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir) (2025.10.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (0.36.0)\n",
            "Requirement already satisfied: packaging in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from datasets->beir) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir) (3.13.2)\n",
            "Requirement already satisfied: anyio in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from httpx<1.0.0->datasets->beir) (4.11.0)\n",
            "Requirement already satisfied: certifi in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from httpx<1.0.0->datasets->beir) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from httpx<1.0.0->datasets->beir) (1.0.9)\n",
            "Requirement already satisfied: idna in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from httpx<1.0.0->datasets->beir) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets->beir) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets->beir) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets->beir) (1.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from requests>=2.32.2->datasets->beir) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from requests>=2.32.2->datasets->beir) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from anyio->httpx<1.0.0->datasets->beir) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from pandas->datasets->beir) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from pandas->datasets->beir) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from pandas->datasets->beir) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->beir) (1.17.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from pytrec-eval-terrier->beir) (1.16.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from sentence-transformers->beir) (4.57.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from sentence-transformers->beir) (2.9.1)\n",
            "Requirement already satisfied: scikit-learn in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from sentence-transformers->beir) (1.7.2)\n",
            "Requirement already satisfied: Pillow in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from sentence-transformers->beir) (12.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->beir) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->beir) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->beir) (0.6.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->beir) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->beir) (3.5)\n",
            "Requirement already satisfied: jinja2 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->beir) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers->beir) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers->beir) (3.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from scikit-learn->sentence-transformers->beir) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/dxu/miniconda3/envs/vec2vec/lib/python3.11/site-packages (from scikit-learn->sentence-transformers->beir) (3.6.0)\n",
            "Downloading beir-2.2.0-py3-none-any.whl (77 kB)\n",
            "Downloading pytrec_eval_terrier-0.5.10-cp311-cp311-macosx_10_9_universal2.whl (136 kB)\n",
            "Installing collected packages: pytrec-eval-terrier, beir\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [beir]\n",
            "\u001b[1A\u001b[2KSuccessfully installed beir-2.2.0 pytrec-eval-terrier-0.5.10\n"
          ]
        }
      ],
      "source": [
        "# !pip install vec2text\n",
        "# !pip install -U typing_extensions\n",
        "# !pip install -q torch torchvision torchaudio\n",
        "# !pip install -q transformers>=4.29.0 sentence-transformers>=2.2.0\n",
        "# !pip install -q datasets\n",
        "# !pip install beir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading NQ dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 5332023/5332023 [00:03<00:00, 1714157.84 examples/s]\n",
            "Generating dev split: 100%|██████████| 849508/849508 [00:00<00:00, 1672897.71 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded: 5332023 examples\n",
            "\n",
            "Sample entry keys: ['text']\n",
            "\n",
            "Sample text (truncated): to a short list of finalists. Ties can occur if the panel decides both entries show equal merit, however they are encouraged to choose a single winner. The judges are selected from a public applicatio...\n",
            "\n",
            " Dataset has 5332023 examples (need 54096 for this run)\n"
          ]
        }
      ],
      "source": [
        "# Test data loading to ensure everything is properly set up\n",
        "import sys\n",
        "sys.path.insert(0, '../vec2vec')\n",
        "\n",
        "from utils.streaming_utils import load_streaming_embeddings\n",
        "\n",
        "# Load the NQ dataset\n",
        "print(\"Loading NQ dataset...\")\n",
        "dset = load_streaming_embeddings(\"nq\")\n",
        "print(f\"Dataset loaded: {len(dset)} examples\")\n",
        "print(f\"\\nSample entry keys: {list(dset[0].keys())}\")\n",
        "\n",
        "# Show a sample\n",
        "sample = dset[0]\n",
        "text_key = 'text' if 'text' in sample else list(sample.keys())[0]\n",
        "print(f\"\\nSample text (truncated): {sample[text_key][:200]}...\")\n",
        "\n",
        "# Confirm we have enough data\n",
        "TRAIN_SIZE = 25000  # per encoder\n",
        "VAL_SIZE = 4096\n",
        "REQUIRED = TRAIN_SIZE * 2 + VAL_SIZE\n",
        "\n",
        "if len(dset) >= REQUIRED:\n",
        "    print(f\"\\n Dataset has {len(dset)} examples (need {REQUIRED} for this run)\")\n",
        "else:\n",
        "    print(f\"\\n Dataset has {len(dset)} examples, adjusting train size...\")\n",
        "    TRAIN_SIZE = (len(dset) - VAL_SIZE) // 2\n",
        "    print(f\"  New train size: {TRAIN_SIZE} per encoder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adversarial Loss Implementation\n",
        "\n",
        "### Original vec2vec GAN Loss\n",
        "The original implementation uses **Least Squares GAN** (LSGAN) with:\n",
        "- Discriminator loss: `0.5 * (D(real)^2 + (D(fake) - 1)^2)`\n",
        "- Generator loss: `0.5 * D(fake)^2`\n",
        "\n",
        "This is applied at:\n",
        "- **Embedding level**: D1 (unsup space), D2 (sup space)\n",
        "- **Latent level**: D_latent (shared latent space)\n",
        "\n",
        "### WGAN-GP (Wasserstein GAN with Gradient Penalty)\n",
        "We implement WGAN-GP with:\n",
        "- **Critic loss**: `E[D(fake)] - E[D(real)] + lambda_gp * gradient_penalty`\n",
        "- **Generator loss**: `-E[D(fake)]`\n",
        "- **Gradient penalty**: `E[(||grad_D(x_interp)||_2 - 1)^2]`\n",
        "\n",
        "Key differences:\n",
        "1. Discriminators are treated as **critics** (no sigmoid, unbounded outputs)\n",
        "2. Uses Wasserstein distance instead of JS divergence\n",
        "3. Gradient penalty enforces 1-Lipschitz constraint\n",
        "4. Generally more stable training dynamics\n",
        "\n",
        "We add a new `gan_style=\"wgan\"` option to toggle this behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WassersteinGAN already exists in utils/gan.py\n",
            "train.py already supports WassersteinGAN\n",
            "\n",
            "Codebase modifications complete!\n"
          ]
        }
      ],
      "source": [
        "# Add WGAN-GP implementation to the codebase\n",
        "import os\n",
        "\n",
        "# Read the current gan.py\n",
        "gan_path = '../vec2vec/utils/gan.py'\n",
        "with open(gan_path, 'r') as f:\n",
        "    gan_code = f.read()\n",
        "\n",
        "# WGAN-GP implementation to add\n",
        "wgan_code = '''\n",
        "\n",
        "class WassersteinGAN(VanillaGAN):\n",
        "    \"\"\"Wasserstein GAN with Gradient Penalty (WGAN-GP).\n",
        "    \n",
        "    Uses Wasserstein distance estimation with gradient penalty\n",
        "    to enforce Lipschitz constraint on the critic.\n",
        "    \"\"\"\n",
        "    \n",
        "    def compute_wgan_gradient_penalty(self, real_data: torch.Tensor, fake_data: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute gradient penalty for WGAN-GP.\n",
        "        \n",
        "        Interpolates between real and fake samples, computes critic output,\n",
        "        and penalizes deviation of gradient norm from 1.\n",
        "        \"\"\"\n",
        "        batch_size = real_data.size(0)\n",
        "        device = real_data.device\n",
        "        \n",
        "        # Random interpolation coefficient\n",
        "        epsilon = torch.rand(batch_size, 1, device=device)\n",
        "        \n",
        "        # Interpolate between real and fake\n",
        "        interpolated = epsilon * real_data + (1 - epsilon) * fake_data\n",
        "        interpolated = interpolated.requires_grad_(True)\n",
        "        \n",
        "        # Get critic output for interpolated samples\n",
        "        d_interpolated = self.discriminator(interpolated)\n",
        "        \n",
        "        # Compute gradients\n",
        "        gradients = torch.autograd.grad(\n",
        "            outputs=d_interpolated,\n",
        "            inputs=interpolated,\n",
        "            grad_outputs=torch.ones_like(d_interpolated),\n",
        "            create_graph=True,\n",
        "            retain_graph=True,\n",
        "        )[0]\n",
        "        \n",
        "        # Compute gradient penalty: (||grad||_2 - 1)^2\n",
        "        gradients = gradients.view(batch_size, -1)\n",
        "        gradient_norm = gradients.norm(2, dim=1)\n",
        "        gradient_penalty = ((gradient_norm - 1) ** 2).mean()\n",
        "        \n",
        "        return gradient_penalty\n",
        "    \n",
        "    def _step_discriminator(self, real_data: torch.Tensor, fake_data: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, float, float]:\n",
        "        \"\"\"WGAN critic update step.\n",
        "        \n",
        "        Critic loss = E[D(fake)] - E[D(real)] + lambda_gp * gradient_penalty\n",
        "        \"\"\"\n",
        "        real_data = real_data.detach()\n",
        "        fake_data = fake_data.detach()\n",
        "        \n",
        "        # Critic outputs (no sigmoid - raw scores)\n",
        "        d_real = self.discriminator(real_data)\n",
        "        d_fake = self.discriminator(fake_data)\n",
        "        \n",
        "        # Wasserstein distance estimate (negative because we want to maximize)\n",
        "        # Critic wants: D(real) high, D(fake) low\n",
        "        # So critic loss = E[D(fake)] - E[D(real)]\n",
        "        wasserstein_dist = d_real.mean() - d_fake.mean()\n",
        "        critic_loss = -wasserstein_dist  # Minimize negative = maximize distance\n",
        "        \n",
        "        # Gradient penalty\n",
        "        gp_lambda = getattr(self.cfg, 'gp_lambda', 10.0)  # Default lambda=10\n",
        "        gradient_penalty = self.compute_wgan_gradient_penalty(real_data, fake_data)\n",
        "        \n",
        "        # Total critic loss\n",
        "        total_critic_loss = critic_loss + gp_lambda * gradient_penalty\n",
        "        \n",
        "        # \"Accuracy\" metrics (for compatibility with logging)\n",
        "        # In WGAN, we use the sign of the output as a proxy\n",
        "        disc_acc_real = (d_real > 0).float().mean().item()\n",
        "        disc_acc_fake = (d_fake < 0).float().mean().item()\n",
        "        \n",
        "        # Backward pass\n",
        "        self.generator.train()\n",
        "        self.discriminator_opt.zero_grad()\n",
        "        self.accelerator.backward(total_critic_loss * self.cfg.loss_coefficient_disc)\n",
        "        self.accelerator.clip_grad_norm_(\n",
        "            self.discriminator.parameters(),\n",
        "            self.cfg.max_grad_norm\n",
        "        )\n",
        "        self.discriminator_opt.step()\n",
        "        self.discriminator_scheduler.step()\n",
        "        \n",
        "        return gradient_penalty.detach(), critic_loss.detach(), disc_acc_real, disc_acc_fake\n",
        "    \n",
        "    def _step_generator(self, real_data: torch.Tensor, fake_data: torch.Tensor) -> tuple[torch.Tensor, float]:\n",
        "        \"\"\"WGAN generator update step.\n",
        "        \n",
        "        Generator loss = -E[D(fake)]\n",
        "        Generator wants critic to think fake samples are real (high scores).\n",
        "        \"\"\"\n",
        "        # Get critic score for fake samples\n",
        "        d_fake = self.discriminator(fake_data)\n",
        "        \n",
        "        # Generator wants to maximize D(fake), so minimize -D(fake)\n",
        "        gen_loss = -d_fake.mean()\n",
        "        \n",
        "        # \"Accuracy\" metric (proxy)\n",
        "        gen_acc = (d_fake > 0).float().mean().item()\n",
        "        \n",
        "        return gen_loss, gen_acc\n",
        "'''\n",
        "\n",
        "# Check if WGAN is already added\n",
        "if 'class WassersteinGAN' not in gan_code:\n",
        "    # Add WGAN-GP implementation\n",
        "    with open(gan_path, 'a') as f:\n",
        "        f.write(wgan_code)\n",
        "    print(\"Added WassersteinGAN class to utils/gan.py\")\n",
        "else:\n",
        "    print(\"WassersteinGAN already exists in utils/gan.py\")\n",
        "\n",
        "# Now update train.py to support the wgan style\n",
        "train_path = '../vec2vec/train.py'\n",
        "with open(train_path, 'r') as f:\n",
        "    train_code = f.read()\n",
        "\n",
        "# Check if we need to add WGAN import and handling\n",
        "if 'WassersteinGAN' not in train_code:\n",
        "    # Update the imports\n",
        "    old_import = 'from utils.gan import LeastSquaresGAN, RelativisticGAN, VanillaGAN'\n",
        "    new_import = 'from utils.gan import LeastSquaresGAN, RelativisticGAN, VanillaGAN, WassersteinGAN'\n",
        "    train_code = train_code.replace(old_import, new_import)\n",
        "    \n",
        "    # Update the GAN style selection\n",
        "    old_selection = '''    if cfg.gan_style == \"vanilla\":\n",
        "        gan_cls = VanillaGAN\n",
        "    elif cfg.gan_style == \"least_squares\":\n",
        "        gan_cls = LeastSquaresGAN\n",
        "    elif cfg.gan_style == \"relativistic\":\n",
        "        gan_cls = RelativisticGAN\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown GAN style: {cfg.gan_style}\")'''\n",
        "    \n",
        "    new_selection = '''    if cfg.gan_style == \"vanilla\":\n",
        "        gan_cls = VanillaGAN\n",
        "    elif cfg.gan_style == \"least_squares\":\n",
        "        gan_cls = LeastSquaresGAN\n",
        "    elif cfg.gan_style == \"relativistic\":\n",
        "        gan_cls = RelativisticGAN\n",
        "    elif cfg.gan_style == \"wgan\":\n",
        "        gan_cls = WassersteinGAN\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown GAN style: {cfg.gan_style}\")'''\n",
        "    \n",
        "    train_code = train_code.replace(old_selection, new_selection)\n",
        "    \n",
        "    with open(train_path, 'w') as f:\n",
        "        f.write(train_code)\n",
        "    print(\"Updated train.py to support gan_style='wgan'\")\n",
        "else:\n",
        "    print(\"train.py already supports WassersteinGAN\")\n",
        "\n",
        "print(\"\\nCodebase modifications complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Configuration\n",
        "\n",
        "We'll use the `unsupervised.toml` config as the base and run two experiments:\n",
        "\n",
        "### Run 1: Baseline GAN (Least Squares)\n",
        "- `gan_style = \"least_squares\"` (original vec2vec)\n",
        "- Standard discriminator with MSE-based loss\n",
        "\n",
        "### Run 2: WGAN-GP\n",
        "- `gan_style = \"wgan\"`\n",
        "- Wasserstein distance with gradient penalty\n",
        "- `gp_lambda = 10` (gradient penalty coefficient)\n",
        "\n",
        "### Shared Hyperparameters for Colab:\n",
        "- **num_points**: 25,000 (samples per encoder, 50k total)\n",
        "- **epochs**: 8 (reduced for faster iteration)\n",
        "- **batch_size**: 128 (reduced for GPU memory)\n",
        "- **learning_rate**: 2e-5 (default)\n",
        "- **mixed_precision**: fp16 (for memory efficiency)\n",
        "\n",
        "All other components (architecture, reconstruction loss, VSP loss, etc.) remain identical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "BASE CONFIGURATION (unsupervised.toml)\n",
            "======================================================================\n",
            "\n",
            "[General]\n",
            "  Dataset: nq\n",
            "  Unsup Model: stella\n",
            "  Sup Model: gte\n",
            "\n",
            "[Translator]\n",
            "  Style: res_mlp\n",
            "  Adapter Dim: 1024\n",
            "\n",
            "[Discriminator]\n",
            "  GAN Style: least_squares\n",
            "  Depth: 5\n",
            "\n",
            "======================================================================\n",
            "SHARED COLAB SETTINGS\n",
            "======================================================================\n",
            "  --num_points 25000\n",
            "  --epochs 8\n",
            "  --bs 128\n",
            "  --val_size 4096\n",
            "  --use_wandb False\n",
            "  --min_epochs 4\n",
            "  --patience 3\n",
            "\n",
            "======================================================================\n",
            "EXPERIMENT CONFIGURATIONS\n",
            "======================================================================\n",
            "\n",
            "[Run 1: Baseline GAN (Least Squares)]\n",
            "  --gan_style least_squares\n",
            "  Output: outputs/vec2vec_colab_50k_gan/\n",
            "\n",
            "[Run 2: WGAN-GP]\n",
            "  --gan_style wgan\n",
            "  --gp_lambda 10\n",
            "  Output: outputs/vec2vec_colab_50k_wgan/\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display and define configurations for both runs\n",
        "import toml\n",
        "import os\n",
        "\n",
        "# Load base config\n",
        "config_path = '../vec2vec/configs/unsupervised.toml'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = toml.load(f)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"BASE CONFIGURATION (unsupervised.toml)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Key settings\n",
        "print(f\"\\n[General]\")\n",
        "print(f\"  Dataset: {config['general']['dataset']}\")\n",
        "print(f\"  Unsup Model: {config['general']['unsup_emb']}\")\n",
        "print(f\"  Sup Model: {config['general']['sup_emb']}\")\n",
        "\n",
        "print(f\"\\n[Translator]\")\n",
        "print(f\"  Style: {config['translator']['style']}\")\n",
        "print(f\"  Adapter Dim: {config['translator']['d_adapter']}\")\n",
        "\n",
        "print(f\"\\n[Discriminator]\")\n",
        "print(f\"  GAN Style: {config['discriminator']['gan_style']}\")\n",
        "print(f\"  Depth: {config['discriminator']['disc_depth']}\")\n",
        "\n",
        "# Define shared Colab settings\n",
        "SHARED_CONFIG = {\n",
        "    'num_points': 25000,       # 25k per encoder (50k total)\n",
        "    'epochs': 8,               # Reduced for Colab\n",
        "    'bs': 128,                 # Reduced batch size for T4\n",
        "    'val_size': 4096,          # Validation set size\n",
        "    'use_wandb': False,        # Disable W&B for simplicity\n",
        "    'min_epochs': 4,           # Lower minimum epochs\n",
        "    'patience': 3,             # Earlier stopping\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SHARED COLAB SETTINGS\")\n",
        "print(\"=\" * 70)\n",
        "for k, v in SHARED_CONFIG.items():\n",
        "    print(f\"  --{k} {v}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EXPERIMENT CONFIGURATIONS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n[Run 1: Baseline GAN (Least Squares)]\")\n",
        "print(\"  --gan_style least_squares\")\n",
        "print(\"  Output: outputs/vec2vec_colab_50k_gan/\")\n",
        "\n",
        "print(\"\\n[Run 2: WGAN-GP]\")\n",
        "print(\"  --gan_style wgan\")\n",
        "print(\"  --gp_lambda 10\")\n",
        "print(\"  Output: outputs/vec2vec_colab_50k_wgan/\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "RUN 1: BASELINE GAN (Least Squares)\n",
            "======================================================================\n",
            "\n",
            "Training command:\n",
            "\n",
            "python train.py unsupervised \\\n",
            "    --num_points 25000 \\\n",
            "    --epochs 8 \\\n",
            "    --bs 128 \\\n",
            "    --val_size 4096 \\\n",
            "    --use_wandb false \\\n",
            "    --min_epochs 4 \\\n",
            "    --patience 3 \\\n",
            "    --gan_style least_squares \\\n",
            "    --save_dir '../vec2vec/outputs/vec2vec_colab_50k_gan/{}' \\\n",
            "    --force_wandb_name true \\\n",
            "    --wandb_name gan_baseline\n",
            "\n",
            "\n",
            "Starting training... (this may take 30-60 minutes on a T4)\n",
            "======================================================================\n",
            "\n",
            "^C\n",
            "object address  : 0x3420bf220\n",
            "object refcount : 2\n",
            "object type     : 0x102d509b8\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n"
          ]
        }
      ],
      "source": [
        "# Run 1: Train with baseline GAN (Least Squares)\n",
        "import os\n",
        "os.chdir('../vec2vec')\n",
        "\n",
        "# Create output directory\n",
        "OUTPUT_DIR_GAN = '../vec2vec/outputs/vec2vec_colab_50k_gan'\n",
        "os.makedirs(OUTPUT_DIR_GAN, exist_ok=True)\n",
        "\n",
        "# Build training command\n",
        "CMD_GAN = f\"\"\"\n",
        "python train.py unsupervised \\\\\n",
        "    --num_points 25000 \\\\\n",
        "    --epochs 8 \\\\\n",
        "    --bs 128 \\\\\n",
        "    --val_size 4096 \\\\\n",
        "    --use_wandb false \\\\\n",
        "    --min_epochs 4 \\\\\n",
        "    --patience 3 \\\\\n",
        "    --gan_style least_squares \\\\\n",
        "    --save_dir '{OUTPUT_DIR_GAN}/{{}}' \\\\\n",
        "    --force_wandb_name true \\\\\n",
        "    --wandb_name gan_baseline\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"RUN 1: BASELINE GAN (Least Squares)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nTraining command:\")\n",
        "print(CMD_GAN)\n",
        "print(\"\\nStarting training... (this may take 30-60 minutes on a T4)\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Run training\n",
        "!{CMD_GAN}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run 2: Train with WGAN-GP\n",
        "import os\n",
        "os.chdir('../vec2vec')\n",
        "\n",
        "# Create output directory\n",
        "OUTPUT_DIR_WGAN = '../vec2vec/outputs/vec2vec_colab_50k_wgan'\n",
        "os.makedirs(OUTPUT_DIR_WGAN, exist_ok=True)\n",
        "\n",
        "# Build training command\n",
        "CMD_WGAN = f\"\"\"\n",
        "python train.py unsupervised \\\\\n",
        "    --num_points 25000 \\\\\n",
        "    --epochs 8 \\\\\n",
        "    --bs 128 \\\\\n",
        "    --val_size 4096 \\\\\n",
        "    --use_wandb false \\\\\n",
        "    --min_epochs 4 \\\\\n",
        "    --patience 3 \\\\\n",
        "    --gan_style wgan \\\\\n",
        "    --gp_lambda 10 \\\\\n",
        "    --save_dir '{OUTPUT_DIR_WGAN}/{{}}' \\\\\n",
        "    --force_wandb_name true \\\\\n",
        "    --wandb_name wgan_gp\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"RUN 2: WGAN-GP\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nTraining command:\")\n",
        "print(CMD_WGAN)\n",
        "print(\"\\nStarting training... (this may take 30-60 minutes on a T4)\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Run training\n",
        "!{CMD_WGAN}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n",
        "\n",
        "We evaluate both trained translators on the same held-out test data using the following metrics:\n",
        "\n",
        "1. **Mean Cosine Similarity**: Average cosine similarity between translated embeddings and true target embeddings (higher is better)\n",
        "2. **Top-1 Accuracy**: Percentage of samples where the translated embedding's nearest neighbor is the correct target (higher is better)\n",
        "3. **Mean Rank**: Average rank of the correct target among all candidates (lower is better)\n",
        "4. **VSP (Vector Space Preservation)**: How well pairwise similarities are preserved after translation (lower is better)\n",
        "\n",
        "The comparison will show whether WGAN-GP improves translation quality over the standard least-squares GAN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate both models and compare results\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from types import SimpleNamespace\n",
        "\n",
        "sys.path.insert(0, '/content/vec2vec')\n",
        "os.chdir('/content/vec2vec')\n",
        "\n",
        "import toml\n",
        "import accelerate\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from utils.collate import MultiencoderTokenizedDataset, TokenizedCollator\n",
        "from utils.eval_utils import eval_loop_, create_heatmap\n",
        "from utils.model_utils import get_sentence_embedding_dimension, load_encoder\n",
        "from utils.utils import load_n_translator, get_num_proc\n",
        "from utils.streaming_utils import load_streaming_embeddings, process_batch\n",
        "\n",
        "def find_checkpoint(base_dir):\n",
        "    \"\"\"Find the model checkpoint directory.\"\"\"\n",
        "    checkpoint_dirs = glob.glob(f\"{base_dir}/**/model.pt\", recursive=True)\n",
        "    if checkpoint_dirs:\n",
        "        return os.path.dirname(sorted(checkpoint_dirs, key=os.path.getmtime)[-1])\n",
        "    return None\n",
        "\n",
        "def evaluate_model(checkpoint_path, test_size=4096):\n",
        "    \"\"\"Evaluate a trained model and return metrics.\"\"\"\n",
        "    if not checkpoint_path:\n",
        "        return None\n",
        "    \n",
        "    # Load config\n",
        "    config_file = os.path.join(checkpoint_path, 'config.toml')\n",
        "    if not os.path.exists(config_file):\n",
        "        print(f\"Config not found: {config_file}\")\n",
        "        return None\n",
        "    \n",
        "    cfg = SimpleNamespace(**toml.load(config_file))\n",
        "    \n",
        "    # Setup accelerator\n",
        "    accelerator = accelerate.Accelerator(\n",
        "        mixed_precision=cfg.mixed_precision if hasattr(cfg, 'mixed_precision') else None\n",
        "    )\n",
        "    accelerator.dataloader_config.dispatch_batches = False\n",
        "    \n",
        "    # Load encoders\n",
        "    sup_encs = {cfg.sup_emb: load_encoder(cfg.sup_emb, mixed_precision=getattr(cfg, 'mixed_precision', None))}\n",
        "    unsup_enc = {cfg.unsup_emb: load_encoder(cfg.unsup_emb, mixed_precision=getattr(cfg, 'mixed_precision', None))}\n",
        "    \n",
        "    # Load translator\n",
        "    encoder_dims = {cfg.sup_emb: get_sentence_embedding_dimension(sup_encs[cfg.sup_emb])}\n",
        "    translator = load_n_translator(cfg, encoder_dims)\n",
        "    unsup_dim = {cfg.unsup_emb: get_sentence_embedding_dimension(unsup_enc[cfg.unsup_emb])}\n",
        "    translator.add_encoders(unsup_dim, overwrite_embs=[cfg.unsup_emb])\n",
        "    \n",
        "    # Load weights\n",
        "    translator.load_state_dict(torch.load(os.path.join(checkpoint_path, 'model.pt'), map_location='cpu'), strict=False)\n",
        "    translator = accelerator.prepare(translator)\n",
        "    translator.eval()\n",
        "    \n",
        "    # Load test data\n",
        "    dset = load_streaming_embeddings(cfg.dataset)\n",
        "    dset_dict = dset.train_test_split(test_size=test_size, seed=cfg.val_dataset_seed)\n",
        "    testset = dset_dict[\"test\"]\n",
        "    \n",
        "    num_workers = min(get_num_proc(), 4)\n",
        "    evalset = MultiencoderTokenizedDataset(\n",
        "        dataset=testset,\n",
        "        encoders={**unsup_enc, **sup_encs},\n",
        "        n_embs_per_batch=2,\n",
        "        batch_size=cfg.val_bs if hasattr(cfg, 'val_bs') else 256,\n",
        "        max_length=cfg.max_seq_length,\n",
        "        seed=cfg.sampling_seed,\n",
        "    )\n",
        "    evalloader = DataLoader(\n",
        "        evalset,\n",
        "        batch_size=cfg.val_bs if hasattr(cfg, 'val_bs') else 256,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=False,\n",
        "        pin_memory=True,\n",
        "        collate_fn=TokenizedCollator(),\n",
        "        drop_last=True,\n",
        "    )\n",
        "    evalloader = accelerator.prepare(evalloader)\n",
        "    \n",
        "    # Run evaluation\n",
        "    with torch.no_grad():\n",
        "        recons, trans, heatmap_dict, _, _, _ = eval_loop_(\n",
        "            cfg, translator, {**sup_encs, **unsup_enc}, evalloader, device=accelerator.device\n",
        "        )\n",
        "    \n",
        "    # Extract metrics\n",
        "    metrics = {\n",
        "        'gan_style': cfg.gan_style,\n",
        "        'train_size': cfg.num_points,\n",
        "        'test_size': test_size,\n",
        "    }\n",
        "    \n",
        "    # Get translation metrics (unsup -> sup)\n",
        "    trans_key = f\"{cfg.unsup_emb}_{cfg.sup_emb}\"\n",
        "    if cfg.sup_emb in trans and cfg.unsup_emb in trans[cfg.sup_emb]:\n",
        "        t = trans[cfg.sup_emb][cfg.unsup_emb]\n",
        "        metrics['cosine'] = t.get('cos', 0)\n",
        "        metrics['vsp'] = t.get('vsp', 0)\n",
        "    \n",
        "    # Get top-1 and rank from heatmap_dict\n",
        "    for k, v in heatmap_dict.items():\n",
        "        if f\"{cfg.unsup_emb}_{cfg.sup_emb}_top_1_acc\" in k:\n",
        "            metrics['top1'] = v\n",
        "        elif f\"{cfg.unsup_emb}_{cfg.sup_emb}_rank\" in k and 'var' not in k:\n",
        "            metrics['rank'] = v\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "# Find checkpoints\n",
        "gan_checkpoint = find_checkpoint('/content/vec2vec/outputs/vec2vec_colab_50k_gan')\n",
        "wgan_checkpoint = find_checkpoint('/content/vec2vec/outputs/vec2vec_colab_50k_wgan')\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"EVALUATING TRAINED MODELS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "results = []\n",
        "\n",
        "# Evaluate GAN baseline\n",
        "if gan_checkpoint:\n",
        "    print(f\"\\nEvaluating GAN baseline: {gan_checkpoint}\")\n",
        "    gan_metrics = evaluate_model(gan_checkpoint)\n",
        "    if gan_metrics:\n",
        "        gan_metrics['adv_type'] = 'GAN (LS)'\n",
        "        results.append(gan_metrics)\n",
        "        print(f\"  Done!\")\n",
        "else:\n",
        "    print(\"\\nGAN baseline checkpoint not found\")\n",
        "\n",
        "# Evaluate WGAN\n",
        "if wgan_checkpoint:\n",
        "    print(f\"\\nEvaluating WGAN-GP: {wgan_checkpoint}\")\n",
        "    wgan_metrics = evaluate_model(wgan_checkpoint)\n",
        "    if wgan_metrics:\n",
        "        wgan_metrics['adv_type'] = 'WGAN-GP'\n",
        "        results.append(wgan_metrics)\n",
        "        print(f\"  Done!\")\n",
        "else:\n",
        "    print(\"\\nWGAN-GP checkpoint not found\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison table\n",
        "import pandas as pd\n",
        "\n",
        "if results:\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(results)\n",
        "    \n",
        "    # Reorder columns\n",
        "    cols = ['adv_type', 'train_size', 'test_size', 'cosine', 'top1', 'rank', 'vsp']\n",
        "    df = df[[c for c in cols if c in df.columns]]\n",
        "    \n",
        "    # Rename for display\n",
        "    df.columns = ['Adv Type', 'Train Size', 'Test Size', 'Cosine', 'Top-1', 'Rank', 'VSP']\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"COMPARISON RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nModel pair: stella -> gte (unsupervised -> supervised)\")\n",
        "    print(\"Dataset: Natural Questions (NQ)\")\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    # Format the table\n",
        "    pd.set_option('display.float_format', lambda x: '%.4f' % x if abs(x) < 100 else '%.1f' % x)\n",
        "    print(df.to_string(index=False))\n",
        "    \n",
        "    print(\"\\n\")\n",
        "    print(\"Metrics explanation:\")\n",
        "    print(\"  Cosine: Mean cosine similarity (higher is better)\")\n",
        "    print(\"  Top-1:  Nearest neighbor accuracy (higher is better)\")\n",
        "    print(\"  Rank:   Mean rank of correct target (lower is better)\")\n",
        "    print(\"  VSP:    Vector space preservation error (lower is better)\")\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    \n",
        "    # Save results\n",
        "    results_path = '/content/vec2vec/outputs/comparison_results.csv'\n",
        "    df.to_csv(results_path, index=False)\n",
        "    print(f\"\\nResults saved to: {results_path}\")\n",
        "else:\n",
        "    print(\"\\nNo results to compare. Please run both training cells first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison plots\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "if results and len(results) >= 2:\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "    \n",
        "    # Extract data\n",
        "    labels = [r['adv_type'] for r in results]\n",
        "    colors = ['#2ecc71', '#3498db']  # Green for GAN, Blue for WGAN\n",
        "    \n",
        "    # Plot 1: Cosine Similarity\n",
        "    if 'cosine' in results[0]:\n",
        "        values = [r.get('cosine', 0) for r in results]\n",
        "        bars = axes[0].bar(labels, values, color=colors)\n",
        "        axes[0].set_ylabel('Cosine Similarity')\n",
        "        axes[0].set_title('Cosine Similarity (higher is better)')\n",
        "        axes[0].set_ylim([min(values) * 0.95, max(values) * 1.02])\n",
        "        for bar, val in zip(bars, values):\n",
        "            axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
        "                        f'{val:.4f}', ha='center', va='bottom', fontsize=10)\n",
        "    \n",
        "    # Plot 2: Top-1 Accuracy\n",
        "    if 'top1' in results[0]:\n",
        "        values = [r.get('top1', 0) for r in results]\n",
        "        bars = axes[1].bar(labels, values, color=colors)\n",
        "        axes[1].set_ylabel('Top-1 Accuracy')\n",
        "        axes[1].set_title('Top-1 Accuracy (higher is better)')\n",
        "        axes[1].set_ylim([0, max(values) * 1.2])\n",
        "        for bar, val in zip(bars, values):\n",
        "            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{val:.4f}', ha='center', va='bottom', fontsize=10)\n",
        "    \n",
        "    # Plot 3: Mean Rank\n",
        "    if 'rank' in results[0]:\n",
        "        values = [r.get('rank', 0) for r in results]\n",
        "        bars = axes[2].bar(labels, values, color=colors)\n",
        "        axes[2].set_ylabel('Mean Rank')\n",
        "        axes[2].set_title('Mean Rank (lower is better)')\n",
        "        axes[2].set_ylim([0, max(values) * 1.3])\n",
        "        for bar, val in zip(bars, values):\n",
        "            axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "                        f'{val:.1f}', ha='center', va='bottom', fontsize=10)\n",
        "    \n",
        "    # Plot 4: VSP Error\n",
        "    if 'vsp' in results[0]:\n",
        "        values = [r.get('vsp', 0) for r in results]\n",
        "        bars = axes[3].bar(labels, values, color=colors)\n",
        "        axes[3].set_ylabel('VSP Error')\n",
        "        axes[3].set_title('VSP Error (lower is better)')\n",
        "        axes[3].set_ylim([0, max(values) * 1.3])\n",
        "        for bar, val in zip(bars, values):\n",
        "            axes[3].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
        "                        f'{val:.4f}', ha='center', va='bottom', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/vec2vec/outputs/comparison_plots.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nPlots saved to: /content/vec2vec/outputs/comparison_plots.png\")\n",
        "else:\n",
        "    print(\"Need results from both runs to create comparison plots.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Discussion\n",
        "\n",
        "### What This Notebook Reproduces\n",
        "\n",
        "This notebook trains and compares two vec2vec translators:\n",
        "\n",
        "1. **Baseline (GAN)**: Original vec2vec with Least Squares GAN loss\n",
        "2. **WGAN-GP**: Vec2vec with Wasserstein GAN + Gradient Penalty\n",
        "\n",
        "Both use:\n",
        "- **50k training examples** (25k per encoder)\n",
        "- **Stella -> GTE** model pair (unsupervised -> supervised)\n",
        "- **ResNet MLP architecture** with adapters\n",
        "- Identical reconstruction, VSP, and cross-chain losses\n",
        "\n",
        "Only the adversarial component differs:\n",
        "- GAN: `L_D = 0.5 * (D(real)^2 + (D(fake)-1)^2)`, `L_G = 0.5 * D(fake)^2`\n",
        "- WGAN: `L_C = E[D(fake)] - E[D(real)] + 10 * GP`, `L_G = -E[D(fake)]`\n",
        "\n",
        "---\n",
        "\n",
        "### Interpreting Results\n",
        "\n",
        "Key questions to consider:\n",
        "\n",
        "1. **Did WGAN-GP improve cosine similarity?**\n",
        "   - Higher cosine = better alignment with target embeddings\n",
        "\n",
        "2. **Did Top-1 accuracy change?**\n",
        "   - Measures exact retrieval performance\n",
        "\n",
        "3. **Did mean rank improve?**\n",
        "   - Lower rank = better overall ranking quality\n",
        "\n",
        "4. **Was training more stable?**\n",
        "   - WGAN-GP typically provides smoother gradients\n",
        "\n",
        "---\n",
        "\n",
        "### Tuning WGAN-GP\n",
        "\n",
        "If WGAN-GP underperforms, try:\n",
        "\n",
        "```python\n",
        "# Adjust gradient penalty coefficient\n",
        "--gp_lambda 1     # Less regularization\n",
        "--gp_lambda 100   # More regularization\n",
        "\n",
        "# Adjust critic learning rate\n",
        "--disc_lr 5e-5    # Higher for WGAN\n",
        "\n",
        "# Multiple critic steps per generator step (not implemented here)\n",
        "# Would require modifying training loop\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Scaling Up\n",
        "\n",
        "To increase training scale:\n",
        "\n",
        "```python\n",
        "# More training data\n",
        "--num_points 100000\n",
        "\n",
        "# More epochs\n",
        "--epochs 30\n",
        "\n",
        "# Larger batch size (if GPU memory allows)\n",
        "--bs 256\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Changing Configurations\n",
        "\n",
        "**Different model pairs:**\n",
        "```python\n",
        "--unsup_emb gte --sup_emb gtr    # GTE to GTR\n",
        "--unsup_emb e5 --sup_emb gte     # E5 to GTE\n",
        "```\n",
        "\n",
        "**Different datasets:**\n",
        "```python\n",
        "--dataset fineweb\n",
        "--dataset msmarco-corpus\n",
        "```\n",
        "\n",
        "**Toggle adversarial modes:**\n",
        "```python\n",
        "--gan_style vanilla         # Standard BCE GAN\n",
        "--gan_style least_squares   # LSGAN (default)\n",
        "--gan_style relativistic    # Relativistic GAN\n",
        "--gan_style wgan            # WGAN-GP\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Citation\n",
        "\n",
        "```bibtex\n",
        "@misc{jha2025harnessinguniversalgeometryembeddings,\n",
        "      title={Harnessing the Universal Geometry of Embeddings}, \n",
        "      author={Rishi Jha and Collin Zhang and Vitaly Shmatikov and John X. Morris},\n",
        "      year={2025},\n",
        "      eprint={2505.12540},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.LG},\n",
        "      url={https://arxiv.org/abs/2505.12540}, \n",
        "}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "vec2vec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
